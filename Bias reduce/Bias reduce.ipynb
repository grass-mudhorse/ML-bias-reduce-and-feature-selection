{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithmic Bias - Core Code\n",
    "Some code to get started on the Algorithmic Bias assignment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "bcDB = datasets.load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcDF = pd.DataFrame(bcDB.data, columns= list(bcDB['feature_names']))\n",
    "bcDF['target'] = pd.Series(bcDB.target)\n",
    "bcDF = bcDF.sort_values(by = ['target'])\n",
    "bcDF = bcDF.reset_index(drop=True)\n",
    "bcDF.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc = bcDF['target'].value_counts()\n",
    "for i,j in enumerate(bcDB.target_names):\n",
    "    print (vc[i],j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = bcDF.pop('target').values\n",
    "X = bcDF.values\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $k$-NN\n",
    "### hold-out testing\n",
    "Malignant is the minority class at ~40%.  \n",
    "$k$-NN classifier picks up this under-representation and accentuates it,  \n",
    "predicting just 36% malignant by hold-out testing method.\n",
    "The mean accuracy of this method is about 91.61%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "kNN = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2)\n",
    "y_pred = kNN.fit(X_train, y_train).predict(X_test)\n",
    "print(X_train.shape,X_test.shape)\n",
    "\n",
    "y_test.sum()/len(y_test)\n",
    "\n",
    "print(\"Malignant in test set : %0.2f\" % (1- (y_test.sum()/len(y_test))))\n",
    "print(\"Predicted malignant : %0.2f\" % (1- (y_pred.sum()/len(y_pred))))\n",
    "model = kNN.fit(X_train, y_train)\n",
    "result = model.score(X_test,y_test)\n",
    "print(\"The mean accuracy of this model is: %0.2f%%\" % (result*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation testing\n",
    "Use cross calidation way with 5 folds set.\n",
    "and the mean accuracy of the method is about 93.41%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "y_pred = cross_val_score(kNN, X, y, cv=5, scoring='f1')\n",
    "print(np.mean(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree\n",
    "### hold-out testing\n",
    "predicting 39% malignant(sometimes 41%) by hold-out testing method. The mean accuracy of this model is: 92.31%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Source\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "\n",
    "dtree = DecisionTreeClassifier(criterion='entropy')\n",
    "tree_graph = dtree.fit(X_train,y_train)\n",
    "y_pred = tree_graph.predict(X_test)\n",
    "\n",
    "print(\"Malignant in test set : %0.2f\" % (1- (y_test.sum()/len(y_test))))\n",
    "print(\"Predicted malignant : %0.2f\" % (1- (y_pred.sum()/len(y_pred))))\n",
    "\n",
    "result = tree_graph.score(X_test,y_test)\n",
    "print(\"The mean accuracy of this model is: %0.2f%%\" % (result*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2,test_size = 0.10)\n",
    "result = tree_graph.score(X_test,y_test)\n",
    "print(\"The mean accuracy of this model is: %0.2f%%\" % (result*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation testing\n",
    "Use cross calidation way with 5 folds set.\n",
    "and the mean accuracy of this method is about 94.57%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cross_val_score(dtree, X, y, cv=5, scoring='f1')\n",
    "np.mean(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process of decision tree shows below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_im = export_graphviz(tree_graph, out_file=None, \n",
    "                      feature_names=bcDB.feature_names,  \n",
    "                      class_names=bcDB.target_names,  \n",
    "                      filled=True, rounded=True,  \n",
    "                      special_characters=True)  \n",
    "graph = Source(tree_im)  \n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "### hold-out testing\n",
    "predicting 37% malignant by hold-out testing method. The mean accuracy of this model is 94.41%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "LR_clf = LogisticRegression().fit(X_train,y_train)\n",
    "y_pred = LR_clf.predict(X_test)\n",
    "\n",
    "print(\"Malignant in test set : %0.2f\" % (1- (y_test.sum()/len(y_test))))\n",
    "print(\"Predicted malignant : %0.2f\" % (1- (y_pred.sum()/len(y_pred))))\n",
    "result = LR_clf.score(X_test,y_test)\n",
    "print(\"The mean accuracy of this model is: %0.2f%%\" % (result*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation testing\n",
    "Use cross calidation way with 5 folds set.\n",
    "and the mean accuracy of this method is 96.13%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cross_val_score( LogisticRegression(), X, y, cv=5, scoring='f1')\n",
    "np.mean(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Navie Bayes\n",
    "### hold-out testing\n",
    "Using the Gaussian Navie Bayes model for hold-out testing and cross-validation testing.\n",
    "Predicting 39% malignant by hold-out testing method.The mean accuracy of this model is: 88.11%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "\n",
    "gnb = GaussianNB().fit(X_train,y_train)\n",
    "y_pred = gnb.predict(X_test)\n",
    "print(\"Malignant in test set : %0.2f\" % (1- (y_test.sum()/len(y_test))))\n",
    "print(\"Predicted malignant : %0.2f\" % (1- (y_pred.sum()/len(y_pred))))\n",
    "result = gnb.score(X_test,y_test)\n",
    "print(\"The mean accuracy of this model is: %0.2f%%\" % (result*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation testing\n",
    "Use cross calidation way with 5 folds set.\n",
    "and the mean accuracy of this method is about 96.13%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cross_val_score(GaussianNB(), X, y, cv=5, scoring='f1')\n",
    "np.mean(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. The strategy to rectify the bias.\n",
    "The inbalanced data leads to the bias. Also a Balanced Accuracy measurement can reduce the bias.\n",
    "For example, f1-measure can reduce the bias and get a balanced accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kNN = KNeighborsClassifier(n_neighbors=3)  \n",
    "dtree = DecisionTreeClassifier(criterion='entropy')\n",
    "LR_clf = LogisticRegression()\n",
    "mnb = GaussianNB()\n",
    "models = [kNN,dtree,LR_clf,mnb]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "for m in models:\n",
    "    mm = m.fit(X_train, y_train)\n",
    "    y_pred = mm.predict(X_test)\n",
    "    f1s = f1_score(y_test, y_pred) \n",
    "    print(\"F1 Score on Test set {:22} {:.4f}\".format(type(m).__name__, f1s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result shows the accuracy score of each method is increased with hold out testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. The second data set to test\n",
    "The second dataset is HotelRevHelpfulnessV2.csv.\n",
    "Using hold-out testing and calculate the scores of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel = pd.read_csv('HotelRevHelpfulnessV2.csv')\n",
    "y = hotel.pop('reviewHelpfulness').values\n",
    "X = hotel.values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=1/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in models:\n",
    "    mm = m.fit(X_train, y_train)\n",
    "    sc = m.score(X_test,y_test) \n",
    "    print(\"Model Score on Test set {:22} {:.4f}\".format(type(m).__name__, sc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using f1 measure to reduce the bias and get a more balanced accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in models:\n",
    "    mm = m.fit(X_train, y_train)\n",
    "    y_pred = mm.predict(X_test)\n",
    "    f1s = f1_score(y_test, y_pred) \n",
    "    print(\"F1 Score on Test set {:22} {:.4f}\".format(type(m).__name__, f1s))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
